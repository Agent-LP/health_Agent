# Sistema RAG de Consejos de Salud

Sistema de recuperaciÃ³n aumentada por generaciÃ³n (RAG) para proporcionar consejos de salud y mejores hÃ¡bitos basados en documentos especializados.

## ğŸ“ Estructura del Proyecto

```
health_RAG/
â”œâ”€â”€ docs/                    # Carpeta para los documentos de salud
â”œâ”€â”€ config.py               # ConfiguraciÃ³n del sistema
â”œâ”€â”€ document_loader.py      # Carga y procesamiento de documentos
â”œâ”€â”€ prompts.py              # Prompts personalizados
â”œâ”€â”€ rag_system.py           # Sistema RAG principal
â”œâ”€â”€ main.py                 # AplicaciÃ³n principal
â”œâ”€â”€ requirements.txt        # Dependencias
â””â”€â”€ README.md              # Este archivo
```

## ğŸš€ InstalaciÃ³n

1. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

2. **AsegÃºrate de tener Ollama instalado y corriendo:**
   - Descarga Ollama desde: https://ollama.ai
   - Instala el modelo que usarÃ¡s (por defecto: `gemma3:1b`):
   ```bash
   ollama pull gemma3:1b
   ```

3. **Coloca tus documentos en la carpeta `docs/`**

## ğŸ“š Sobre los Documentos

### Â¿QuÃ© formato de nombres usar?

**Respuesta corta:** Cualquier nombre descriptivo funciona bien.

**Recomendaciones:**
- Puedes usar cualquier nombre que te resulte Ãºtil: `nutricion.pdf`, `ejercicio_fisico.txt`, `habitos_sueno.docx`, etc.
- El sistema detecta automÃ¡ticamente el tipo de archivo por su extensiÃ³n
- Los nombres descriptivos te ayudarÃ¡n a identificar quÃ© documentos se estÃ¡n usando en las respuestas

**Formatos soportados:**
- `.pdf` - Archivos PDF
- `.txt` - Archivos de texto plano
- `.md` - Archivos Markdown
- `.docx` - Documentos de Word

### Ejemplos de nombres Ãºtiles:
```
docs/
â”œâ”€â”€ nutricion_basica.pdf
â”œâ”€â”€ ejercicios_cardio.txt
â”œâ”€â”€ habitos_sueno.md
â”œâ”€â”€ salud_mental.docx
â””â”€â”€ cualquier_nombre.pdf  # TambiÃ©n funciona
```

## ğŸ¯ Uso

### Ejecutar la aplicaciÃ³n:

```bash
python main.py
```

### Modo interactivo:

Una vez iniciado, puedes:
- Hacer preguntas sobre salud y hÃ¡bitos
- Cambiar el nÃºmero de documentos consultados escribiendo `docs N` (ej: `docs 6`)
- Escribir `salir` o `exit` para terminar

### Ejemplo de uso:

```
Tu pregunta: Â¿CuÃ¡les son los mejores hÃ¡bitos para dormir bien?

Buscando informaciÃ³n relevante...

============================================================
RESPUESTA:
============================================================
[La respuesta basada en tus documentos]

ğŸ“š Documentos consultados (4):
  1. habitos_sueno.md
  2. salud_mental.docx
  ...
```

## âš™ï¸ ConfiguraciÃ³n

Puedes modificar la configuraciÃ³n en `config.py`:

- `LLM_MODEL`: Modelo de Ollama a usar
- `RETRIEVER_K`: NÃºmero de documentos a recuperar por defecto
- `CHUNK_SIZE`: TamaÃ±o de los chunks de texto
- `CHUNK_OVERLAP`: Solapamiento entre chunks

## ğŸ” CÃ³mo Funciona

1. **Carga de documentos:** El sistema carga todos los documentos de la carpeta `docs/`
2. **Procesamiento:** Divide los documentos en chunks mÃ¡s pequeÃ±os
3. **IndexaciÃ³n:** Crea un Ã­ndice vectorial usando embeddings
4. **BÃºsqueda:** Cuando haces una pregunta, busca los documentos mÃ¡s relevantes
5. **GeneraciÃ³n:** El LLM genera una respuesta basada en los documentos encontrados

## ğŸ“ Notas

- El sistema solo usa informaciÃ³n de los documentos proporcionados
- Si no encuentra informaciÃ³n relevante, lo indicarÃ¡ claramente
- Puedes ajustar cuÃ¡ntos documentos consultar segÃºn la complejidad de tu pregunta
- Los documentos se cargan automÃ¡ticamente al iniciar la aplicaciÃ³n

## ğŸ› ï¸ SoluciÃ³n de Problemas

**Error: "No se encontraron documentos"**
- AsegÃºrate de tener archivos en la carpeta `docs/`
- Verifica que los archivos tengan una extensiÃ³n soportada

**Error: "Modelo no encontrado"**
- Verifica que Ollama estÃ© corriendo: `ollama list`
- Instala el modelo: `ollama pull gemma3:1b`

**Respuestas lentas:**
- Reduce el nÃºmero de documentos consultados (`docs 2`)
- Usa un modelo mÃ¡s pequeÃ±o
- Reduce el `CHUNK_SIZE` en `config.py`





